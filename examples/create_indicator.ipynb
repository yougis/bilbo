{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data_to_calculate = [\n",
    "    #\"H3_6_NC_non_traite\",\n",
    "    #\"H3_6_NC_non_traite_2010\",\n",
    "    \"H3_6_NC\"\n",
    "]\n",
    "\n",
    "steplist= [1,2,3]  # 1 : generate indicators by spatial intersection (interpolation/raster/vector)/ 2: spliting byDims & calculate ratio... / 3: persist\n",
    "list_indicateur_to_calculate = [\n",
    "    \"KBA\",\n",
    "    #\"observation_nidification\"\n",
    "    #\"GFC_gain_2012\",\n",
    "    #\"GFC_treecover2000\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "listIdSpatialNC = [\"0\"]\n",
    "listIdSpatialCommune = [\n",
    "    \"98827\", \"98817\", \"98813\", \"98826\", \"98819\", \"98816\", \"98828\", \"98824\", \"98832\", \"98821\", \n",
    "    \"98831\", \"98818\", \"98804\", \"98822\", \"98814\", \"98815\", \"98806\", \"98809\", \"98820\", \"98811\", \n",
    "    \"98807\", \"98805\", \"98803\", \"98823\", \"98810\", \"98812\", \"98833\", \"98808\", \"98825\", \"98801\", \n",
    "    \"98830\", \"98802\", \"98829\"\n",
    "]\n",
    "\n",
    "Poya = [\"98827\"]\n",
    "listIdSpatialCommuneMaritime = [\n",
    "    \"MONT_DORE\", \"LA_FOA\", \"POUM\", \"OUEGOA\", \"MOINDOU\", \"SARRAMEA\", \"POUEBO\", \"YATE\", \"PAITA\", \n",
    "    \"VOH\", \"NOUMEA\", \"CANALA\", \"POINDIMIE\", \"LIFOU\", \"MARE\", \"FARINO\", \"ILE_DES_PINS\", \"OUVEA\", \n",
    "    \"KONE\", \"POYA\", \"HIENGHENE\", \"DUMBEA\", \"BOURAIL\", \"PONERIHOUEN\", \"KAALA_GOMEN\", \"KOUMAC\", \n",
    "    \"KOUAOUA\", \"HOUAILOU\", \"POUEMBOUT\", \"BELEP\", \"TOUHO\", \"BOULOUPARI\", \"THIO\"\n",
    "]\n",
    "\n",
    "listIdSpatialProvinceMaritime = ['PROVINCE_SUD_MAR', 'PROVINCE_NORD_MAR', 'PROVINCE_ILES_MAR']\n",
    "listIdSpatialProvince = [\"1\", \"2\", \"3\"]\n",
    "listIdSpatialHER = [\"C\", \"F\", \"G\", \"B\", \"D\", \"A\", \"E\"]\n",
    "listIdSpatialRegHydro = [\n",
    "    \"0100\", \"0200\", \"0300\", \"0400\", \"0505\", \"0600\", \"0700\", \"0800\", \"0900\", \"1000\", \"1100\", \n",
    "    \"1400\", \"1500\", \"1600\", \"1700\", \"1800\", \"1900\", \"2000\", \"2100\", \"2200\", \"2300\", \"2400\", \n",
    "    \"2500\", \"2700\", \"2800\", \"2900\", \"3100\", \"3200\", \"3300\", \"3400\", \"3500\", \"3600\", \"3700\", \n",
    "    \"3800\", \"3900\", \"4000\", \"4100\", \"4300\", \"4400\", \"4500\", \"4600\", \"4700\", \"4800\", \"4900\", \n",
    "    \"5000\", \"5100\", \"5200\", \"5300\", \"5500\", \"5600\", \"5700\", \"5800\", \"5900\", \"6000\", \"6100\", \n",
    "    \"6200\", \"6400\", \"6500\", \"6600\", \"6700\", \"6800\", \"6900\", \"7000\", \"7100\", \"7200\", \"7300\", \n",
    "    \"7400\", \"7500\", \"7700\", \"7800\", \"7900\", \"8000\", \"8100\", \"8200\", \"8300\", \"8400\", \"8500\", \n",
    "    \"8600\", \"8700\", \"8800\", \"8900\", \"9000\", \"9100\", \"9200\", \"0301\", \"4200\", \"2600\", \"0302\", \n",
    "    \"0501\", \"2602\", \"0502\", \"5400\", \"1602\", \"0503\", \"0504\", \"0500\", \"1601\", \"2601\", \"2603\", \n",
    "    \"3000\", \"7600\", \"6300\", \"1200\", \"1300\"\n",
    "]\n",
    "\n",
    "listIdSpatialAiresCoutumieres = [\n",
    "    \"AJIE-ARO\", \"DJUBEA-KAPONE\", \"DREHU\", \"HOOT MA WHAAP\", \"IAII\", \"NENGONE\", \"PAICI-CAMUKI\", \"XARACUU\"\n",
    "]\n",
    "listIdSpatialZee = [\"ZEE\"]\n",
    "\n",
    "listIdSpatialCommuneIles = [\"98814\", \"98815\", \"98820\"]\n",
    "listIdSpatialCommuneMaritimeIles = [\"LIFOU\", \"MARE\", \"OUVEA\"]\n",
    "listIdSpatialProvinceIles = [\"3\"]\n",
    "listIdSpatialProvinceMaritimeIles = [\"PROVINCE_DES_ILES_MAR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "listIdMulti=[listIdSpatialNC, listIdSpatialHER, listIdSpatialProvince, listIdSpatialCommune ]\n",
    "listbbox= [c for c in listIdSpatialCommune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20/02/2024 15:32:24 - INFO - Config - Settings Imported\n",
      "20/02/2024 15:32:24 - WARNING - The following variables are null: commun_path, project_dir, data_catalog_dir, data_output_dir, sig_data_path, project_db_schema\n",
      "20/02/2024 15:32:24 - INFO - Utils - Connection Imported\n",
      "20/02/2024 15:32:24 - INFO - Utils - Dataframe Imported\n",
      "20/02/2024 15:32:24 - INFO - Utils - Geometry Imported\n",
      "20/02/2024 15:32:24 - DEBUG - Could not import boto3, continuing with reduced functionality.\n",
      "20/02/2024 15:32:24 - INFO - Utils - Raster Imported\n",
      "20/02/2024 15:32:25 - DEBUG - Could not import boto3, continuing with reduced functionality.\n",
      "20/02/2024 15:32:25 - DEBUG - GDAL_DATA found in environment.\n",
      "20/02/2024 15:32:25 - DEBUG - PROJ_DATA found in environment.\n",
      "20/02/2024 15:32:25 - INFO - GeoIndicator - Gee Imported\n",
      "20/02/2024 15:32:25 - INFO - Utils - Interpolation Imported\n",
      "20/02/2024 15:32:25 - INFO - GeoIndicator - Distribution Imported\n",
      "20/02/2024 15:32:25 - INFO - GeoIndicator - Raster Imported\n",
      "20/02/2024 15:32:25 - INFO - GeoIndicator - Calculation Imported\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from oeilnc_config import settings\n",
    "import yaml\n",
    "import logging\n",
    "from oeilnc_utils import connection\n",
    "from oeilnc_geoindicator.calculation import create_indicator\n",
    "from intake import open_catalog\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%d/%m/%Y %H:%M:%S', level=logging.CRITICAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20/02/2024 15:33:23 - INFO - Config - Settings Imported\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20/02/2024 15:33:23 - WARNING - La variable d'environnement SCHEDULER_IP doit être renseignée pour effectuer les traitements de manière distribuée\n",
      "20/02/2024 15:33:23 - INFO - on applique cette ip par défaut : 172.20.12.13:9786\n",
      "20/02/2024 15:33:23 - DEBUG - Using selector: EpollSelector\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'conf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m client \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mgetDaskClient()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitializeWorkers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m config \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39minitializeBilboProject(dotenvPath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.dev_env\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m config\n",
      "File \u001b[0;32m/opt/conda/envs/gis311/lib/python3.11/site-packages/distributed/client.py:2998\u001b[0m, in \u001b[0;36mClient.run\u001b[0;34m(self, function, workers, wait, nanny, on_error, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2915\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m   2916\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2917\u001b[0m     function,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2923\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2924\u001b[0m ):\n\u001b[1;32m   2925\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2926\u001b[0m \u001b[38;5;124;03m    Run a function on all workers outside of task scheduling system\u001b[39;00m\n\u001b[1;32m   2927\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2996\u001b[0m \u001b[38;5;124;03m    >>> c.run(print_state, wait=False)  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m   2997\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2998\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2999\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3001\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnanny\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnanny\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3005\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3006\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3007\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/gis311/lib/python3.11/site-packages/distributed/utils.py:358\u001b[0m, in \u001b[0;36mSyncMethodMixin.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/gis311/lib/python3.11/site-packages/distributed/utils.py:434\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m         wait(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 434\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/envs/gis311/lib/python3.11/site-packages/distributed/utils.py:408\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    406\u001b[0m         awaitable \u001b[38;5;241m=\u001b[39m wait_for(awaitable, timeout)\n\u001b[1;32m    407\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(awaitable)\n\u001b[0;32m--> 408\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m future\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    410\u001b[0m     error \u001b[38;5;241m=\u001b[39m exception\n",
      "File \u001b[0;32m/opt/conda/envs/gis311/lib/python3.11/site-packages/tornado/gen.py:767\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 767\u001b[0m         value \u001b[38;5;241m=\u001b[39m future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    769\u001b[0m         \u001b[38;5;66;03m# Save the exception for later. It's important that\u001b[39;00m\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;66;03m# gen.throw() not be called inside this try/except block\u001b[39;00m\n\u001b[1;32m    771\u001b[0m         \u001b[38;5;66;03m# because that makes sys.exc_info behave unexpectedly.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m         exc: Optional[\u001b[38;5;167;01mException\u001b[39;00m] \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m/opt/conda/envs/gis311/lib/python3.11/site-packages/distributed/client.py:2903\u001b[0m, in \u001b[0;36mClient._run\u001b[0;34m(self, function, nanny, workers, wait, on_error, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2900\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 2903\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   2904\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m on_error \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2905\u001b[0m     results[key] \u001b[38;5;241m=\u001b[39m exc\n",
      "File \u001b[0;32m~/projets/bilbo-packages/oeilnc_config/settings.py:109\u001b[0m, in \u001b[0;36minitializeWorkers\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m db_externe \u001b[38;5;241m=\u001b[39m getenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDB_EXT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m config_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpswd\u001b[39m\u001b[38;5;124m\"\u001b[39m: pswd,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension_catalog_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: dimension_catalog_dir\n\u001b[1;32m    107\u001b[0m }\n\u001b[0;32m--> 109\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWorkers Settings - getPaths - config \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conf' is not defined"
     ]
    }
   ],
   "source": [
    "client = settings.getDaskClient()\n",
    "\n",
    "client.run(settings.initializeWorkers)\n",
    "\n",
    "config = settings.initializeBilboProject(dotenvPath='.dev_env')\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "                    \n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "                \n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "                    \n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20/02/2024 15:32:31 - DEBUG - open file: /media/commun/commun/Informatique/SIG/Application/Jupyterhub/projets/catalogFiles/DWH_Dimensions.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20/02/2024 15:32:31 - INFO - step list : {steplist}\n",
      "20/02/2024 15:32:31 - INFO - Initial offset : 600 , limit : 100\n",
      "20/02/2024 15:32:31 - INFO - Id Spatial qui seront calculés : ['0', 'C', 'F', 'G', 'B', 'D', 'A', 'E', '1', '2', '3', '98827', '98817', '98813', '98826', '98819', '98816', '98828', '98824', '98832', '98821', '98831', '98818', '98804', '98822', '98814', '98815', '98806', '98809', '98820', '98811', '98807', '98805', '98803', '98823', '98810', '98812', '98833', '98808', '98825', '98801', '98830', '98802', '98829']\n",
      "20/02/2024 15:32:31 - INFO - individu: H3_6_NC\n",
      "20/02/2024 15:32:31 - INFO - indicateur: KBA\n",
      "20/02/2024 15:32:31 - INFO - le nom de la table de faits en base de donnée en sortie de traitement répond au pré-requis : faits_kba_h3_nc_6\n",
      "20/02/2024 15:32:31 - INFO - nbchuncks: 300\n",
      "20/02/2024 15:32:31 - DEBUG - open file: /home/hugo/projets/bilbo-packages/examples/../test_catalog_file/h3.yaml\n",
      "20/02/2024 15:32:31 - INFO - {'sources': {'compte_entites': {'driver': 'sql', 'metadata': {}, 'args': {'uri': 'postgresql://{{env(\"DB_USER\")}}:{{env(\"DB_PWD\")}}@{{env(\"DB_HOST\")}}:{{env(\"DB_PORT\")}}/oeil_traitement', 'sql_expr': 'SELECT COUNT(*) as nb FROM bilbo.h3_nc_6;'}, 'description': 'Compter le nombre d’entités sans charger les géométries'}}}\n",
      "20/02/2024 15:32:31 - DEBUG - open file: /home/hugo/projets/bilbo-packages/examples/tmp.yaml\n",
      "20/02/2024 15:32:31 - INFO - bilbo.h3_nc_6 nblignes : 759\n",
      "20/02/2024 15:32:31 - INFO - sql_pagination : order by hex_id limit 100 offset 600\n",
      "20/02/2024 15:32:31 - INFO - Dask client : <Client: 'tcp://172.21.0.5:8786' processes=1 threads=12, memory=31.20 GiB>\n",
      "20/02/2024 15:32:31 - INFO - Settings - getPaths data_config_file ../test_catalog_file/config/ \n",
      "20/02/2024 15:32:31 - DEBUG - Settings - getPaths - config {'commun_path': '/media/commun/commun/', 'project_dir': '/media/commun/commun/Informatique/SIG/Application/Jupyterhub/projets/stac/', 'data_catalog_dir': '../test_catalog_file/', 'data_output_dir': '../target/', 'sig_data_path': '/media/commun/commun/Informatique/SIG/Donnees/', 'project_db_schema': 'bilbo', 'data_config_file': '../test_catalog_file/config/', 'dimension_catalog_dir': '/media/commun/commun/Informatique/SIG/Application/Jupyterhub/projets/catalogFiles/'}\n",
      "20/02/2024 15:32:31 - INFO - create_indicator: Etape 1\n",
      "20/02/2024 15:32:31 - DEBUG - open file: /home/hugo/projets/bilbo-packages/examples/../test_catalog_file/h3.yaml\n",
      "20/02/2024 15:32:31 - INFO - create_indicator: Etape 1 sans bbox\n",
      "20/02/2024 15:32:31 - INFO - create_indicator: Etape 1 --> indicateurSpec.get('catalogUri') and indicateurSpec.get('dataName') is not None\n",
      "20/02/2024 15:32:31 - INFO - create_indicator: Etape 1 --> sourceType : None\n",
      "20/02/2024 15:32:31 - INFO - source Type OTHER : ex . VECTOR \n",
      "20/02/2024 15:32:31 - DEBUG - open file: /home/hugo/projets/bilbo-packages/examples/../test_catalog_file/data_reference.yaml\n",
      "20/02/2024 15:32:31 - INFO - Calculation ...\n",
      "20/02/2024 15:32:31 - INFO - with Dask - metaModelList : ' ['hex_id', 'kba', 'geometry', 'id_split']\n",
      "20/02/2024 15:32:31 - INFO - reading intake source  sources:\n",
      "  h3_nc_6:\n",
      "    args:\n",
      "      geopandas_kwargs:\n",
      "        crs: 3163\n",
      "        geom_col: geometry\n",
      "      sql_expr: select  hex_id, geometry from bilbo.h3_nc_6 order by hex_id limit\n",
      "        100 offset 600\n",
      "      table: bilbo.h3_nc_6\n",
      "      uri: postgresql://hroussaffa:mcot@172.20.12.13:5432/oeil_traitement\n",
      "    description: \"Maille H3 niveau 6 sur les terres emerg\\xE9es de NC\"\n",
      "    driver: intake_geopandas.geopandas.PostGISSource\n",
      "    metadata:\n",
      "      catalog_dir: /home/hugo/projets/bilbo-packages/examples/../test_catalog_file/\n",
      "...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sources:\n",
      "  h3_nc_6:\n",
      "    args:\n",
      "      geopandas_kwargs:\n",
      "        crs: 3163\n",
      "        geom_col: geometry\n",
      "      sql_expr: select  hex_id, geometry from bilbo.h3_nc_6\n",
      "      table: bilbo.h3_nc_6\n",
      "      uri: postgresql://hroussaffa:mcot@172.20.12.13:5432/oeil_traitement\n",
      "    description: \"Maille H3 niveau 6 sur les terres emerg\\xE9es de NC\"\n",
      "    driver: intake_geopandas.geopandas.PostGISSource\n",
      "    metadata:\n",
      "      catalog_dir: /home/hugo/projets/bilbo-packages/examples/../test_catalog_file/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20/02/2024 15:32:32 - DEBUG - df: 100\n",
      "20/02/2024 15:32:32 - DEBUG - metaModelList ['hex_id', 'kba', 'geometry', 'id_split']\n",
      "20/02/2024 15:32:32 - DEBUG - Load data in memory (100, 2)\n",
      "20/02/2024 15:32:32 - DEBUG - converting to dask with chunksize 300\n",
      "20/02/2024 15:32:32 - DEBUG - PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      "20/02/2024 15:32:32 - DEBUG - data : Dask GeoDataFrame Structure:\n",
      "                 hex_id  geometry\n",
      "npartitions=100                  \n",
      "0                string  geometry\n",
      "1                   ...       ...\n",
      "...                 ...       ...\n",
      "99                  ...       ...\n",
      "99                  ...       ...\n",
      "Dask Name: to_pyarrow_string, 2 graph layers\n",
      "20/02/2024 15:32:32 - DEBUG - func : <function generateIndicateur_parallel_v2 at 0x7fc859276ca0>\n",
      "20/02/2024 15:32:32 - INFO - Etape 1 - Result:  <class 'dask_geopandas.core.GeoDataFrame'>\n",
      "20/02/2024 15:32:32 - INFO - Etape 1 - Result:  <Future: pending, key: finalize-8c8f01ac9337d6591c35da4e9a81650a>\n",
      "20/02/2024 15:32:32 - INFO - create_indicator: Etape 2\n",
      "20/02/2024 15:32:32 - INFO - indexListIndicator None\n",
      "20/02/2024 15:32:32 - INFO - create_indicator: Etape 2 --> pas de indexListIndicator\n",
      "20/02/2024 15:32:32 - DEBUG - create_indicator: Etape 2 -->  indicateur Dask GeoDataFrame Structure:\n",
      "                 hex_id     kba  geometry id_split\n",
      "npartitions=100                                   \n",
      "0                string  string  geometry   string\n",
      "1                   ...     ...       ...      ...\n",
      "...                 ...     ...       ...      ...\n",
      "99                  ...     ...       ...      ...\n",
      "99                  ...     ...       ...      ...\n",
      "Dask Name: to_pyarrow_string, 1 graph layer\n",
      "20/02/2024 15:32:32 - INFO - indicateurSpec {'adaptingDataframe': {'renameMap': {'level': 'type_spatial', 'upper_libelle': 'dimension_spatiale', 'objectid': 'id_thematique'}, 'setAllClasseValue': 'Zone clé pour la biodiversité', 'setValue': {'colName': 'id_indicateur', 'value': 32}, 'toDrop': []}, 'catalogUri': 'data_reference.yaml', 'confDb': {'chunksize': 1000, 'schema': 'bilbo', 'strategy': 'append', 'tableName': 'kba'}, 'confDims': {'isin_id_mesure': [3], 'isin_id_spatial': ['ZEE']}, 'confRatio': {'indexList': ['ogc_fid', 'id_spatial'], 'ratioByIdSpatial': ['ZEE'], 'rationalizeBy': 'values'}, 'dataName': 'kba', 'indexRef': 'ogc_fid', 'indicateur_dissolve_byList': [], 'keepList': ['kba'], 'nbchuncks': 1, 'overlayHow': 'intersection'}\n",
      "20/02/2024 15:32:32 - INFO - create_indicator: Etape 2 --> metaModelList ['hex_id', 'kba', 'id_split', 'id_spatial', 'level', 'upper_libelle', 'geometry']\n",
      "20/02/2024 15:32:32 - INFO - generateValueBydims error: Error during deserialization of the task graph. This frequently\n",
      "occurs if the Scheduler and Client have different environments.\n",
      "For more information, see\n",
      "https://docs.dask.org/en/stable/deployment-considerations.html#consistent-software-environments\n",
      "\n",
      "20/02/2024 15:32:32 - INFO - create_indicator: Etape 3 --> persisting in database: confDb {'chunksize': 1000, 'schema': 'bilbo', 'strategy': 'append', 'tableName': 'kba'}\n",
      "20/02/2024 15:32:32 - DEBUG - create_indicator: Etape 3 --> Indicateur Dask GeoDataFrame Structure:\n",
      "                 hex_id     kba  geometry id_split\n",
      "npartitions=100                                   \n",
      "0                string  string  geometry   string\n",
      "1                   ...     ...       ...      ...\n",
      "...                 ...     ...       ...      ...\n",
      "99                  ...     ...       ...      ...\n",
      "99                  ...     ...       ...      ...\n",
      "Dask Name: to_pyarrow_string, 1 graph layer\n",
      "20/02/2024 15:32:32 - INFO - create_indicator: Etape 3 --> Resultat 0     (to_pyarrow_string-cca08751ce1b36ee75006353797...\n",
      "1     (to_pyarrow_string-cca08751ce1b36ee75006353797...\n",
      "2     (to_pyarrow_string-cca08751ce1b36ee75006353797...\n",
      "3     (to_pyarrow_string-cca08751ce1b36ee75006353797...\n",
      "4     (to_pyarrow_string-cca08751ce1b36ee75006353797...\n",
      "                            ...                        \n",
      "95    (to_pyarrow_string-cca08751ce1b36ee75006353797...\n",
      "96    (to_pyarrow_string-cca08751ce1b36ee75006353797...\n",
      "97    (to_pyarrow_string-cca08751ce1b36ee75006353797...\n",
      "98    (to_pyarrow_string-cca08751ce1b36ee75006353797...\n",
      "99    (to_pyarrow_string-cca08751ce1b36ee75006353797...\n",
      "Length: 100, dtype: object\n",
      "20/02/2024 15:32:32 - INFO - persistGDF error: (psycopg2.OperationalError) connection to server at \"172.20.12.13\", port 5432 failed: FATAL:  database \"None\" does not exist\n",
      "\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "20/02/2024 15:32:32 - INFO - sql_pagination : order by hex_id limit 100 offset 700\n",
      "20/02/2024 15:32:32 - INFO - Dask client : <Client: 'tcp://172.21.0.5:8786' processes=1 threads=12, memory=31.20 GiB>\n",
      "20/02/2024 15:32:32 - INFO - Settings - getPaths data_config_file ../test_catalog_file/config/ \n",
      "20/02/2024 15:32:32 - DEBUG - Settings - getPaths - config {'commun_path': '/media/commun/commun/', 'project_dir': '/media/commun/commun/Informatique/SIG/Application/Jupyterhub/projets/stac/', 'data_catalog_dir': '../test_catalog_file/', 'data_output_dir': '../target/', 'sig_data_path': '/media/commun/commun/Informatique/SIG/Donnees/', 'project_db_schema': 'bilbo', 'data_config_file': '../test_catalog_file/config/', 'dimension_catalog_dir': '/media/commun/commun/Informatique/SIG/Application/Jupyterhub/projets/catalogFiles/'}\n",
      "20/02/2024 15:32:32 - INFO - create_indicator: Etape 1\n",
      "20/02/2024 15:32:32 - DEBUG - open file: /home/hugo/projets/bilbo-packages/examples/../test_catalog_file/h3.yaml\n",
      "20/02/2024 15:32:32 - INFO - create_indicator: Etape 1 sans bbox\n",
      "20/02/2024 15:32:32 - INFO - create_indicator: Etape 1 --> indicateurSpec.get('catalogUri') and indicateurSpec.get('dataName') is not None\n",
      "20/02/2024 15:32:32 - INFO - create_indicator: Etape 1 --> sourceType : None\n",
      "20/02/2024 15:32:32 - INFO - source Type OTHER : ex . VECTOR \n",
      "20/02/2024 15:32:32 - DEBUG - open file: /home/hugo/projets/bilbo-packages/examples/../test_catalog_file/data_reference.yaml\n",
      "20/02/2024 15:32:32 - INFO - Calculation ...\n",
      "20/02/2024 15:32:32 - INFO - with Dask - metaModelList : ' ['hex_id', 'kba', 'geometry', 'id_split']\n",
      "20/02/2024 15:32:32 - INFO - reading intake source  sources:\n",
      "  h3_nc_6:\n",
      "    args:\n",
      "      geopandas_kwargs:\n",
      "        crs: 3163\n",
      "        geom_col: geometry\n",
      "      sql_expr: select  hex_id, geometry from bilbo.h3_nc_6 order by hex_id limit\n",
      "        100 offset 700\n",
      "      table: bilbo.h3_nc_6\n",
      "      uri: postgresql://hroussaffa:mcot@172.20.12.13:5432/oeil_traitement\n",
      "    description: \"Maille H3 niveau 6 sur les terres emerg\\xE9es de NC\"\n",
      "    driver: intake_geopandas.geopandas.PostGISSource\n",
      "    metadata:\n",
      "      catalog_dir: /home/hugo/projets/bilbo-packages/examples/../test_catalog_file/\n",
      "...\n",
      "20/02/2024 15:32:32 - DEBUG - df: 59\n",
      "20/02/2024 15:32:32 - DEBUG - metaModelList ['hex_id', 'kba', 'geometry', 'id_split']\n",
      "20/02/2024 15:32:32 - DEBUG - Load data in memory (59, 2)\n",
      "20/02/2024 15:32:32 - DEBUG - converting to dask with chunksize 300\n",
      "20/02/2024 15:32:32 - DEBUG - PROJ_ERROR: proj_create: unrecognized format / unknown name\n",
      "20/02/2024 15:32:32 - DEBUG - data : Dask GeoDataFrame Structure:\n",
      "                hex_id  geometry\n",
      "npartitions=59                  \n",
      "0               string  geometry\n",
      "1                  ...       ...\n",
      "...                ...       ...\n",
      "58                 ...       ...\n",
      "58                 ...       ...\n",
      "Dask Name: to_pyarrow_string, 2 graph layers\n",
      "20/02/2024 15:32:32 - DEBUG - func : <function generateIndicateur_parallel_v2 at 0x7fc859276ca0>\n",
      "20/02/2024 15:32:32 - INFO - Etape 1 - Result:  <class 'dask_geopandas.core.GeoDataFrame'>\n",
      "20/02/2024 15:32:32 - INFO - Etape 1 - Result:  <Future: pending, key: finalize-438ef113d32ad90fb372c522ca8593e6>\n",
      "20/02/2024 15:32:32 - INFO - create_indicator: Etape 2\n",
      "20/02/2024 15:32:32 - INFO - indexListIndicator None\n",
      "20/02/2024 15:32:32 - INFO - create_indicator: Etape 2 --> pas de indexListIndicator\n",
      "20/02/2024 15:32:32 - DEBUG - create_indicator: Etape 2 -->  indicateur Dask GeoDataFrame Structure:\n",
      "                hex_id     kba  geometry id_split\n",
      "npartitions=59                                   \n",
      "0               string  string  geometry   string\n",
      "1                  ...     ...       ...      ...\n",
      "...                ...     ...       ...      ...\n",
      "58                 ...     ...       ...      ...\n",
      "58                 ...     ...       ...      ...\n",
      "Dask Name: to_pyarrow_string, 1 graph layer\n",
      "20/02/2024 15:32:32 - INFO - indicateurSpec {'adaptingDataframe': {'renameMap': {'level': 'type_spatial', 'upper_libelle': 'dimension_spatiale', 'objectid': 'id_thematique'}, 'setAllClasseValue': 'Zone clé pour la biodiversité', 'setValue': {'colName': 'id_indicateur', 'value': 32}, 'toDrop': []}, 'catalogUri': 'data_reference.yaml', 'confDb': {'chunksize': 1000, 'schema': 'bilbo', 'strategy': 'append', 'tableName': 'kba'}, 'confDims': {'isin_id_mesure': [3], 'isin_id_spatial': ['ZEE']}, 'confRatio': {'indexList': ['ogc_fid', 'id_spatial'], 'ratioByIdSpatial': ['ZEE'], 'rationalizeBy': 'values'}, 'dataName': 'kba', 'indexRef': 'ogc_fid', 'indicateur_dissolve_byList': [], 'keepList': ['kba'], 'nbchuncks': 1, 'overlayHow': 'intersection'}\n",
      "20/02/2024 15:32:32 - INFO - create_indicator: Etape 2 --> metaModelList ['hex_id', 'kba', 'id_split', 'id_spatial', 'level', 'upper_libelle', 'geometry']\n",
      "20/02/2024 15:32:32 - INFO - generateValueBydims error: Error during deserialization of the task graph. This frequently\n",
      "occurs if the Scheduler and Client have different environments.\n",
      "For more information, see\n",
      "https://docs.dask.org/en/stable/deployment-considerations.html#consistent-software-environments\n",
      "\n",
      "20/02/2024 15:32:32 - INFO - create_indicator: Etape 3 --> persisting in database: confDb {'chunksize': 1000, 'schema': 'bilbo', 'strategy': 'append', 'tableName': 'kba'}\n",
      "20/02/2024 15:32:32 - DEBUG - create_indicator: Etape 3 --> Indicateur Dask GeoDataFrame Structure:\n",
      "                hex_id     kba  geometry id_split\n",
      "npartitions=59                                   \n",
      "0               string  string  geometry   string\n",
      "1                  ...     ...       ...      ...\n",
      "...                ...     ...       ...      ...\n",
      "58                 ...     ...       ...      ...\n",
      "58                 ...     ...       ...      ...\n",
      "Dask Name: to_pyarrow_string, 1 graph layer\n",
      "20/02/2024 15:32:32 - INFO - create_indicator: Etape 3 --> Resultat 0     (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "1     (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "2     (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "3     (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "4     (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "5     (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "6     (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "7     (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "8     (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "9     (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "10    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "11    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "12    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "13    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "14    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "15    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "16    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "17    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "18    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "19    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "20    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "21    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "22    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "23    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "24    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "25    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "26    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "27    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "28    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "29    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "30    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "31    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "32    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "33    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "34    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "35    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "36    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "37    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "38    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "39    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "40    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "41    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "42    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "43    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "44    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "45    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "46    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "47    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "48    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "49    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "50    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "51    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "52    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "53    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "54    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "55    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "56    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "57    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "58    (to_pyarrow_string-8ef2db791ac15447ac3270d31e7...\n",
      "dtype: object\n",
      "20/02/2024 15:32:32 - INFO - persistGDF error: (psycopg2.OperationalError) connection to server at \"172.20.12.13\", port 5432 failed: FATAL:  database \"None\" does not exist\n",
      "\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 655 ms, sys: 29.5 ms, total: 684 ms\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bboxing = False #par emprise communale\n",
    "bb=None\n",
    "fromIndexList=False\n",
    "steplist= [1,2,3]# 1 : generate indicators / 2: spliting byDims & calculate ratio... / 3: persist\n",
    "info_integration = False\n",
    "sql_pagination = \"\"\n",
    "indicateur_sql_flow=True # si Vrai, attention à ne pas depasser le nombre de connection postgres maximales avec la somme de chunck de l'ensemble du cluster\n",
    "daskComputation=True\n",
    "faits = list()\n",
    "theme=config.get('project_db_schema')\n",
    "\n",
    "\n",
    "cat_dimensions = open_catalog(f\"{config.get('dimension_catalog_dir')}DWH_Dimensions.yaml\")\n",
    "\n",
    "dim_spatial = cat_dimensions.dim_spatial\n",
    "dim_mesure= cat_dimensions.dim_mesure\n",
    "\n",
    "for dataFileName in list_data_to_calculate:\n",
    "    with open(f\"{config.get('data_config_file')}{dataFileName}.yaml\", 'r') as file:        \n",
    "        individuStatSpec = yaml.load(file, Loader=yaml.Loader)\n",
    "        individuStatSpec[\"theme\"]=theme\n",
    "        individuStatSpec[\"confDims\"][\"isin_id_spatial\"] = []\n",
    "\n",
    "        logging.info(\"step list : {steplist}\")\n",
    "        if fromIndexList:            \n",
    "            indexList = settings.getIndexList(individuStatSpec)\n",
    "            pass\n",
    "        for listIdSpatial in listIdMulti:\n",
    "            individuStatSpec[\"confDims\"][\"isin_id_spatial\"]+=listIdSpatial\n",
    "            \n",
    "        if len(list_indicateur_to_calculate) > 0:\n",
    "            for indicateurFileName in list_indicateur_to_calculate:\n",
    "                offset = individuStatSpec.get(\"offset\", -1)                \n",
    "                limit = individuStatSpec.get(\"limit\", -1)\n",
    "\n",
    "                logging.info(f\"Initial offset : {offset} , limit : {limit}\")\n",
    "                \n",
    "                logging.info(f\"Id Spatial qui seront calculés : {individuStatSpec['confDims']['isin_id_spatial']}\")\n",
    "                \n",
    "                \n",
    "                with open(f\"{config.get('data_config_file')}{indicateurFileName}.yaml\", 'r') as file:\n",
    "                    indicateurSpec = yaml.load(file, Loader=yaml.Loader)\n",
    "                    indicateurSpec[\"confDb\"][\"schema\"] = theme\n",
    "                    logging.info(f\"individu: {dataFileName}\")\n",
    "                    logging.info(f\"indicateur: {indicateurFileName}\")\n",
    "\n",
    "                    if not fromIndexList:\n",
    "                        indexList= None\n",
    "\n",
    "                    if settings.checkConfig(indicateurSpec,individuStatSpec) :                                        \n",
    "                        logging.info(f\"nbchuncks: {individuStatSpec.get('nbchuncks','aucun')}\")\n",
    "\n",
    "                        if offset >= 0 or limit > 0:        \n",
    "                            #Ajout JFNGVS = boucle sur limit et offset\n",
    "                            catalog = f\"{config.get('data_catalog_dir')}{individuStatSpec.get('catalogUri',None)}\"\n",
    "\n",
    "                            dataName = individuStatSpec.get('dataName',None)\n",
    "                            entryCatalog = getattr(open_catalog(catalog),dataName)\n",
    "                            selectString = individuStatSpec.get('selectString',entryCatalog.describe().get('args').get('sql_expr'))\n",
    "                            indexRef = individuStatSpec.get('indexRef',None)\n",
    "                            print(entryCatalog)                   \n",
    "                            nbLignes = connection.getNbLignes(entryCatalog) \n",
    "\n",
    "                            while offset < nbLignes:\n",
    "                                \n",
    "                                sql_pagination = f\"order by {indexRef} limit {limit} offset {offset}\"\n",
    "                                logging.info(f\"sql_pagination : {sql_pagination}\")\n",
    "                                \n",
    "\n",
    "                                faitsname = create_indicator(bbox=bb, \n",
    "                                                                            individuStatSpec=individuStatSpec,\n",
    "                                                                            indicateurSpec=indicateurSpec,\n",
    "                                                                            dims=(dim_spatial,dim_mesure),\n",
    "                                                                            stepList=steplist,\n",
    "                                                                            indexListIndicator=indexList,\n",
    "                                                                            sql_pagination=sql_pagination,\n",
    "                                                                    indicateur_sql_flow=indicateur_sql_flow,\n",
    "                                                                    daskComputation=daskComputation)\n",
    "                                offset += limit\n",
    "                    else : \n",
    "                        pass\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.getDaskClient().get_versions(check=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
